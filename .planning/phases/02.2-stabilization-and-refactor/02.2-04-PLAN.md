---
phase: 02.2-stabilization-and-refactor
plan: 04
type: execute
wave: 2
depends_on: ["02.2-01"]
files_modified:
  - src/lib/ai/model-engine.ts
  - src/store/modelStore.ts
  - src/App.tsx
  - src/routes/ChatDetailRoute.tsx
autonomous: true
requirements:
  - TECH-07
  - TECH-08
must_haves:
  truths:
    - Model loads automatically on hard refresh at /chat
    - No duplicate model loading requests
    - Model state persists correctly across navigation
    - Chat works immediately after page refresh
  artifacts:
    - path: src/lib/ai/model-engine.ts
      provides: Industry-level model engine with deduplication
      exports: ["modelEngine", "ModelEngine"]
    - path: src/store/modelStore.ts
      provides: Updated to use ModelEngine
      pattern: "Uses modelEngine singleton"
    - path: src/App.tsx
      provides: Model initialization check on mount
      pattern: "useEffect for model init check"
  key_links:
    - from: src/store/modelStore.ts
      to: src/lib/ai/model-engine.ts
      via: modelEngine singleton
      pattern: "modelEngine.loadModel"
    - from: src/App.tsx
      to: src/store/modelStore.ts
      via: "loadModel action"
      pattern: "loadModel if no model loaded"
---

<objective>
Build industry-level Model Engine that handles model loading on hard refresh, prevents duplicate requests, and manages model state correctly across navigation.

Purpose: Fix the critical bug where hard refresh at /chat fails with "model not loaded" error. Create a robust foundation for model management.
Output: ModelEngine class with deduplication, proper state management, and automatic initialization.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02.2-stabilization-and-refactor/02.2-CONTEXT.md
@.planning/audit/STABILITY_AUDIT.md

## Critical Bug: Model Loading Fails on Hard Refresh

From CONTEXT.md:
- Hard refresh at `/chat` → "model not loaded" error
- Only works when going through landing page → loading screen → /chat
- Root cause: No model initialization check at `/chat` route, assumes model is always loaded

## No Request Deduplication

From STABILITY_AUDIT.md Section 4.4:
```typescript
loadModel: async (modelId: string) => {
  // No check for duplicate in-flight requests
  set({ isLoading: true, ... });
  await inferenceManager.initialize(modelId, ...);
}
```

## Decisions from CONTEXT.md

- **Solution:** Build industry-level Model Engine that:
  - Checks model existence on app mount
  - Gracefully loads model if not loaded
  - Handles model switches seamlessly
  - Uses AI SDK patterns where possible
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create ModelEngine with deduplication</name>
  <files>src/lib/ai/model-engine.ts</files>
  <action>
Create src/lib/ai/model-engine.ts - Industry-level model management:

```typescript
/**
 * Model Engine - Industry-level model management
 *
 * Handles model lifecycle with:
 * - Request deduplication (prevents duplicate loads)
 * - State persistence across navigation
 * - Automatic initialization on mount
 * - Clean error handling with recovery
 */

import { inferenceManager, type DownloadProgress } from "./inference";
import { getModelById, type ModelConfig } from "./models";

/**
 * Model loading state
 */
export type ModelLoadingState =
  | { kind: "idle" }
  | { kind: "loading"; modelId: string; abort: () => void }
  | { kind: "ready"; model: ModelConfig }
  | { kind: "error"; error: string; modelId: string };

/**
 * Model Engine - Singleton for model lifecycle management
 *
 * Features:
 * - Deduplication: Multiple load requests for same model are coalesced
 * - Cancellation: In-flight loads can be cancelled
 * - State tracking: Current state always available synchronously
 * - Event callbacks: Subscribe to state changes
 */
export class ModelEngine {
  private state: ModelLoadingState = { kind: "idle" };
  private listeners: Set<(state: ModelLoadingState) => void> = new Set();
  private progressCallback: ((progress: DownloadProgress) => void) | null = null;

  /**
   * Get current state (synchronous)
   */
  getState(): ModelLoadingState {
    return this.state;
  }

  /**
   * Check if a model is currently loaded and ready
   */
  isReady(): boolean {
    return this.state.kind === "ready";
  }

  /**
   * Get currently loaded model (null if not ready)
   */
  getCurrentModel(): ModelConfig | null {
    return this.state.kind === "ready" ? this.state.model : null;
  }

  /**
   * Check if a specific model is currently loading
   */
  isLoading(modelId?: string): boolean {
    if (this.state.kind !== "loading") return false;
    if (modelId) return this.state.modelId === modelId;
    return true;
  }

  /**
   * Subscribe to state changes
   * @returns Unsubscribe function
   */
  subscribe(listener: (state: ModelLoadingState) => void): () => void {
    this.listeners.add(listener);
    // Immediately call with current state
    listener(this.state);
    return () => {
      this.listeners.delete(listener);
    };
  }

  /**
   * Set progress callback for download updates
   */
  setProgressCallback(callback: ((progress: DownloadProgress) => void) | null): void {
    this.progressCallback = callback;
  }

  /**
   * Load a model with deduplication
   *
   * If same model is already loading, returns existing promise.
   * If different model is loading, cancels it first.
   * If model is already loaded, returns immediately.
   */
  async loadModel(modelId: string): Promise<void> {
    const model = getModelById(modelId);
    if (!model) {
      const error = `Model not found: ${modelId}`;
      this.setState({ kind: "error", error, modelId });
      throw new Error(error);
    }

    // Already loaded this model?
    if (this.state.kind === "ready" && this.state.model.id === modelId) {
      return;
    }

    // Currently loading this same model?
    if (this.state.kind === "loading" && this.state.modelId === modelId) {
      // Wait for existing load to complete
      await this.waitForLoad();
      return;
    }

    // Loading a different model? Cancel it first
    if (this.state.kind === "loading") {
      this.state.abort();
      // Small delay to let cleanup happen
      await new Promise((resolve) => setTimeout(resolve, 100));
    }

    // Start new load
    const abortController = new AbortController();

    this.setState({
      kind: "loading",
      modelId,
      abort: () => abortController.abort(),
    });

    try {
      await inferenceManager.initialize(modelId, (progress) => {
        // Check if aborted
        if (abortController.signal.aborted) {
          return;
        }
        this.progressCallback?.(progress);
      });

      // Check again after async operation
      if (abortController.signal.aborted) {
        throw new Error("Loading was cancelled");
      }

      this.setState({ kind: "ready", model });
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : "Unknown error";
      this.setState({ kind: "error", error: errorMessage, modelId });
      throw error;
    }
  }

  /**
   * Unload current model
   */
  unload(): void {
    // Cancel any in-flight loading
    if (this.state.kind === "loading") {
      this.state.abort();
    }

    inferenceManager.terminate();
    this.setState({ kind: "idle" });
  }

  /**
   * Retry loading after error
   */
  async retry(): Promise<void> {
    if (this.state.kind !== "error") {
      throw new Error("No error to retry from");
    }
    return this.loadModel(this.state.modelId);
  }

  /**
   * Wait for current load to complete (or fail)
   */
  private waitForLoad(): Promise<void> {
    return new Promise((resolve, reject) => {
      const unsubscribe = this.subscribe((state) => {
        if (state.kind === "ready") {
          unsubscribe();
          resolve();
        } else if (state.kind === "error") {
          unsubscribe();
          reject(new Error(state.error));
        }
        // Keep waiting if still loading
      });
    });
  }

  /**
   * Update state and notify listeners
   */
  private setState(newState: ModelLoadingState): void {
    this.state = newState;
    this.listeners.forEach((listener) => {
      try {
        listener(newState);
      } catch (e) {
        console.error("ModelEngine listener error:", e);
      }
    });
  }
}

/**
 * Singleton instance
 */
export const modelEngine = new ModelEngine();
```

This provides:
- Deduplication: Same model load request coalesced
- Cancellation: In-flight loads can be aborted
- State machine: Clear idle/loading/ready/error states
- Observable: Subscribe to state changes
  </action>
  <verify>grep -q "export class ModelEngine" src/lib/ai/model-engine.ts && grep -q "isLoading" src/lib/ai/model-engine.ts && grep -q "loadModel" src/lib/ai/model-engine.ts</verify>
  <done>ModelEngine created with deduplication, cancellation, and state management</done>
</task>

<task type="auto">
  <name>Task 2: Update modelStore to use ModelEngine</name>
  <files>src/store/modelStore.ts</files>
  <action>
Refactor src/store/modelStore.ts to use ModelEngine:

```typescript
/**
 * Model Store - Reactive state management for AI models
 *
 * Uses ModelEngine for actual operations, providing Zustand
 * interface for React components.
 */

import { create } from "zustand";
import { devtools } from "zustand/middleware";
import { modelEngine, type ModelLoadingState } from "@/lib/ai/model-engine";
import { MODELS, getModelById, type ModelConfig } from "@/lib/ai/models";
import type { DownloadProgress } from "@/lib/ai/inference";

type LoadingStep = "idle" | "downloading" | "compiling" | "ready" | "error";

interface ModelState {
  // State
  currentModel: ModelConfig | null;
  isLoading: boolean;
  downloadProgress: DownloadProgress | null;
  loadingStep: LoadingStep;
  error: string | null;
  availableModels: ModelConfig[];

  // Actions
  loadModel: (modelId: string) => Promise<void>;
  cancelDownload: () => void;
  resetModel: () => void;
  clearError: () => void;
}

export const useModelStore = create<ModelState>()(
  devtools(
    (set, get) => {
      // Subscribe to ModelEngine state changes
      modelEngine.subscribe((engineState) => {
        const { currentModel, isLoading, loadingStep, error } = get();

        // Map engine state to store state
        let newState: Partial<ModelState> = {};

        switch (engineState.kind) {
          case "idle":
            newState = {
              currentModel: null,
              isLoading: false,
              loadingStep: "idle" as const,
              error: null,
            };
            break;
          case "loading":
            newState = {
              isLoading: true,
              loadingStep: "downloading" as const,
              error: null,
            };
            break;
          case "ready":
            newState = {
              currentModel: engineState.model,
              isLoading: false,
              loadingStep: "ready" as const,
              error: null,
            };
            break;
          case "error":
            newState = {
              isLoading: false,
              loadingStep: "error" as const,
              error: engineState.error,
            };
            break;
        }

        // Only update if changed (prevent infinite loops)
        if (
          newState.currentModel !== currentModel ||
          newState.isLoading !== isLoading ||
          newState.loadingStep !== loadingStep ||
          newState.error !== error
        ) {
          set(newState);
        }
      });

      // Set up progress callback
      modelEngine.setProgressCallback((progress) => {
        set({ downloadProgress: progress });
      });

      return {
        // Initial state
        currentModel: null,
        isLoading: false,
        downloadProgress: null,
        loadingStep: "idle",
        error: null,
        availableModels: MODELS,

        /**
         * Load a model by ID
         * Delegates to ModelEngine with deduplication
         */
        loadModel: async (modelId: string) => {
          // Validate model exists
          const model = getModelById(modelId);
          if (!model) {
            set({
              error: `Model not found: ${modelId}`,
              loadingStep: "error",
            });
            return;
          }

          try {
            await modelEngine.loadModel(modelId);
          } catch (err) {
            // Error is already set by ModelEngine subscription
            if (import.meta.env.DEV) {
              console.error("[ModelStore] Load failed:", err);
            }
          }
        },

        /**
         * Cancel ongoing download
         */
        cancelDownload: () => {
          modelEngine.unload();
        },

        /**
         * Reset to idle state
         */
        resetModel: () => {
          modelEngine.unload();
        },

        /**
         * Clear error state
         */
        clearError: () => {
          set({ error: null });
          // Also clear engine error by going to idle
          if (modelEngine.getState().kind === "error") {
            modelEngine.unload();
          }
        },
      };
    },
    { name: "ModelStore" }
  )
);

// Selector hooks (unchanged)
export const useCurrentModel = () => useModelStore((state) => state.currentModel);
export const useIsLoading = () => useModelStore((state) => state.isLoading);
export const useDownloadProgress = () => useModelStore((state) => state.downloadProgress);
export const useLoadingStep = () => useModelStore((state) => state.loadingStep);
export const useModelError = () => useModelStore((state) => state.error);
export const useAvailableModels = () => useModelStore((state) => state.availableModels);
export const useLoadModel = () => useModelStore((state) => state.loadModel);
export const useCancelDownload = () => useModelStore((state) => state.cancelDownload);
export const useResetModel = () => useModelStore((state) => state.resetModel);
```

Key changes:
- Subscribe to ModelEngine state changes
- Delegate loadModel to ModelEngine (gets deduplication)
- Progress callback set up once at init
- Actions call ModelEngine methods
  </action>
  <verify>grep -q "modelEngine" src/store/modelStore.ts && grep -q "modelEngine.subscribe" src/store/modelStore.ts</verify>
  <done>modelStore refactored to use ModelEngine singleton</done>
</task>

<task type="auto">
  <name>Task 3: Add model initialization check in App.tsx</name>
  <files>src/App.tsx</files>
  <action>
Update src/App.tsx to check and initialize model on mount:

Current App.tsx doesn't check if model is loaded when navigating directly to /chat.

Add to AppContent component:

```typescript
/**
 * AppContent component - Router content with routes
 */
function AppContent() {
  const navigate = useNavigate();

  // Settings store
  const hasCompletedSetup = useSettingsStore(selectHasCompletedSetup);
  const isSettingsLoading = useSettingsStore((state) => state.isLoading);
  const loadSettings = useSettingsStore((state) => state.loadSettings);

  // Model store
  const currentModel = useModelStore((state) => state.currentModel);
  const loadModel = useModelStore((state) => state.loadModel);
  const loadingStep = useModelStore((state) => state.loadingStep);

  // Load settings on mount
  useEffect(() => {
    loadSettings();
  }, [loadSettings]);

  // Check if user has completed setup and redirect to chat if so
  useEffect(() => {
    if (!isSettingsLoading && hasCompletedSetup && currentModel) {
      if (window.location.pathname === "/") {
        navigate("/chat");
      }
    }
  }, [hasCompletedSetup, currentModel, isSettingsLoading, navigate]);

  // CRITICAL: Check if model needs to be loaded when at /chat routes
  useEffect(() => {
    const path = window.location.pathname;
    const isChatRoute = path.startsWith("/chat");

    if (isChatRoute && !currentModel && loadingStep === "idle") {
      // User is on chat route but no model loaded
      // Load the default model
      if (import.meta.env.DEV) {
        console.log("[App] Chat route with no model, auto-loading...");
      }
      loadModel(QUICK_MODEL.id);
    }
  }, [currentModel, loadingStep, loadModel]);

  // Rest of component unchanged...
```

This ensures:
- When user refreshes at /chat, model loads automatically
- When user navigates directly to /chat/[id], model loads
- No infinite loops (checks loadingStep === "idle")
- Uses default model (QUICK_MODEL) for auto-load
  </action>
  <verify>grep -q "isChatRoute" src/App.tsx && grep -q "auto-loading" src/App.tsx</verify>
  <done>App.tsx checks for model on chat routes and auto-loads if needed</done>
</task>

<task type="auto">
  <name>Task 4: Update ChatDetailRoute to handle loading state</name>
  <files>src/routes/ChatDetailRoute.tsx</files>
  <action>
Update src/routes/ChatDetailRoute.tsx to show loading state when model is not ready:

```typescript
/**
 * ChatDetailRoute Component - Handles /chat/[id]
 *
 * Loads conversation from storage and renders chat interface.
 * Shows loading state if model is not ready.
 */

import { useEffect, useState } from "react";
import { useParams } from "react-router-dom";
import { Loader2 } from "lucide-react";
import { AIChatInterface } from "@/components/Chat/AIChatInterface";
import { useModelStore } from "@/store/modelStore";
import { getConversation } from "@/lib/storage/conversations";
import type { Conversation } from "@/types/index";

export function ChatDetailRoute() {
  const { id } = useParams<{ id: string }>();
  const [conversation, setConversation] = useState<Conversation | null>(null);
  const [isLoading, setIsLoading] = useState(true);
  const [error, setError] = useState<string | null>(null);

  // Model state
  const currentModel = useModelStore((state) => state.currentModel);
  const isModelLoading = useModelStore((state) => state.isLoading);
  const modelError = useModelStore((state) => state.error);

  // Load conversation from storage
  useEffect(() => {
    if (!id) return;

    const loadConversation = async () => {
      setIsLoading(true);
      setError(null);

      try {
        const conv = await getConversation(id);
        if (conv) {
          setConversation(conv);
        } else {
          setError("Conversation not found");
        }
      } catch (err) {
        setError(err instanceof Error ? err.message : "Failed to load conversation");
      } finally {
        setIsLoading(false);
      }
    };

    loadConversation();
  }, [id]);

  // Show loading while fetching conversation
  if (isLoading) {
    return (
      <div className="flex h-full flex-col items-center justify-center bg-[#FFF8F0]">
        <Loader2 className="h-8 w-8 animate-spin text-[#FF6B35]" />
        <p className="mt-4 text-gray-600">Loading conversation...</p>
      </div>
    );
  }

  // Show error if conversation not found
  if (error || !conversation) {
    return (
      <div className="flex h-full flex-col items-center justify-center bg-[#FFF8F0]">
        <p className="text-red-500">{error || "Conversation not found"}</p>
        <button
          onClick={() => window.location.reload()}
          className="mt-4 rounded-lg bg-[#FF6B35] px-4 py-2 text-white hover:bg-[#FF6B35]/90"
        >
          Retry
        </button>
      </div>
    );
  }

  // Show loading while model is initializing
  if (isModelLoading) {
    return (
      <div className="flex h-full flex-col items-center justify-center bg-[#FFF8F0]">
        <Loader2 className="h-8 w-8 animate-spin text-[#FF6B35]" />
        <p className="mt-4 text-gray-600">Loading AI model...</p>
        <p className="mt-2 text-sm text-gray-500">This may take a moment on first load</p>
      </div>
    );
  }

  // Show error if model failed to load
  if (modelError) {
    return (
      <div className="flex h-full flex-col items-center justify-center bg-[#FFF8F0]">
        <p className="text-red-500">Failed to load model</p>
        <p className="mt-2 text-sm text-gray-600">{modelError}</p>
        <button
          onClick={() => window.location.reload()}
          className="mt-4 rounded-lg bg-[#FF6B35] px-4 py-2 text-white hover:bg-[#FF6B35]/90"
        >
          Retry
        </button>
      </div>
    );
  }

  // Show message if no model loaded (shouldn't happen with auto-load)
  if (!currentModel) {
    return (
      <div className="flex h-full flex-col items-center justify-center bg-[#FFF8F0]">
        <p className="text-gray-600">No model loaded</p>
        <button
          onClick={() => window.location.href = "/loading"}
          className="mt-4 rounded-lg bg-[#FF6B35] px-4 py-2 text-white hover:bg-[#FF6B35]/90"
        >
          Load Model
        </button>
      </div>
    );
  }

  // Render chat interface
  return (
    <AIChatInterface
      conversationId={conversation.id}
      modelId={currentModel.id}
      initialMessages={conversation.messages}
    />
  );
}
```

This provides clear loading states and error recovery for:
- Conversation loading
- Model initialization
- Model errors
- Missing model (fallback)
  </action>
  <verify>grep -q "isModelLoading" src/routes/ChatDetailRoute.tsx && grep -q "Loading AI model" src/routes/ChatDetailRoute.tsx</verify>
  <done>ChatDetailRoute shows loading states for model initialization</done>
</task>

</tasks>

<verification>
- ModelEngine deduplicates load requests
- App.tsx auto-loads model on chat routes
- ChatDetailRoute shows loading state during model init
- Hard refresh at /chat now works
- No duplicate model loading requests
</verification>

<success_criteria>
- ModelEngine created with deduplication and cancellation
- modelStore uses ModelEngine singleton
- App.tsx checks and auto-loads model on chat routes
- ChatDetailRoute handles loading/error states
- Hard refresh at /chat works correctly
</success_criteria>

<output>
After completion, create `.planning/phases/02.2-stabilization-and-refactor/02.2-04-SUMMARY.md`
</output>
