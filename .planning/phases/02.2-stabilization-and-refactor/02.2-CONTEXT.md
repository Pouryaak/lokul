# Phase 2.2: Stabilization & Refactor - Context

**Gathered:** 2026-02-18
**Status:** Ready for planning

<domain>
## Phase Boundary

Stabilize the existing chat functionality by refactoring to industry-level standards. No new capabilities—just make what exists robust, maintainable, and modular.

**Core problems to solve:**
- Race conditions in conversation persistence
- Memory leaks in WebLLM transport
- Non-functional abort/stop generation
- Dual state management confusion (legacy + AI SDK)
- Inconsistent error handling patterns
- Tight coupling between layers

**Success criteria:**
- Zero race conditions in critical paths
- Clean separation of concerns (UI / Business Logic / Infrastructure)
- Consistent error handling with user-friendly recovery
- All async operations properly cancellable
- Defensive programming (guards, validation, cleanup)

</domain>

<decisions>
## Implementation Decisions

### State Management Architecture
- **Single source of truth:** AI SDK UI for chat state, Zustand for UI/app state only
- **Remove legacy:** Delete old chatStore.ts and useChat.ts after migration
- **Async state:** Use React Query patterns for server-adjacent operations (model loading, persistence)

### Error Handling Standard
- **Pattern:** Result<T, E> types or structured error objects, not thrown exceptions
- **User feedback:** Toast for user errors, console for dev details, error boundary for crashes
- **Recovery:** Every error state must have a recovery path (retry, dismiss, fallback)

### Async Operation Patterns
- **Cancellation:** All long-running operations accept AbortSignal
- **Deduplication:** In-flight request tracking to prevent duplicate operations
- **Cleanup:** useEffect and event listeners properly disposed
- **Loading states:** Explicit state machine (idle → loading → success/error)

### Code Organization
- **Component size:** Max 200 lines, extract at 150
- **Function size:** Max 50 lines, single responsibility
- **File structure:** Co-locate related files (component, test, styles, types)
- **Naming:** Explicit over concise (e.g., `isModelLoading` not `loading`)

### Defensive Programming
- **Input validation:** Validate at system boundaries (user input, external APIs)
- **Null checks:** No implicit any, no unchecked optional chaining
- **Race protection:** Optimistic locking for storage operations
- **Resource limits:** Context window management, max retry limits

### Claude's Discretion
- Specific library choices for Result types (ts-pattern, neverthrow, or custom)
- Exact folder structure within src/
- Specific naming conventions beyond the general principle
- Testing strategy details (test locations, coverage targets)

</decisions>

<specifics>
## Specific Ideas

**Reference architectures:**
- "Like Linear's codebase" — clean separation, predictable patterns
- React Query's architecture for async state
- tRPC's type-safety patterns

**Must-fix from audit:**
1. Abort implementation (currently console.log("Stop requested"))
2. Debounce persistence (race condition on rapid messages)
3. Memory leak in transport (event listener cleanup)
4. Request deduplication in model loading
5. Remove legacy components (ChatInterface.tsx, etc.)

**Critical User-Reported Bugs (must fix in this phase):**

1. **Ghost Conversations Bug** (`ChatRoute.tsx`, `useConversations.ts`)
   - Opening `/chat` renders 20+ deleted conversations
   - Shows "conversation not found" toasts repeatedly
   - Gets stuck in "creating new conversation" loop
   - Root cause: Stale activeConversationId in chatStore, race condition between deletion and navigation

2. **Duplicate Conversations in Sidebar** (`AppSidebar.tsx`, `useConversations.ts`)
   - Same conversation appearing multiple times in sidebar
   - Root cause: Likely duplicate entries in IndexedDB or rendering issue with keys

3. **Model Loading Fails on Hard Refresh** (`App.tsx`, `modelStore.ts`)
   - Hard refresh at `/chat` → "model not loaded" error
   - Only works when going through landing page → loading screen → /chat
   - Root cause: No model initialization check at `/chat` route, assumes model is always loaded
   - **Solution:** Build industry-level Model Engine that:
     - Checks model existence on app mount
     - Gracefully loads model if not loaded
     - Handles model switches seamlessly
     - Uses AI SDK patterns where possible

**Quality gates:**
- No `any` types except in type guards
- No console.log in production code paths
- No useEffect without cleanup consideration
- All async functions have error handling

**AI SDK Patterns to Use:**
- Use `useChat` from `@ai-sdk/react` properly with `initialMessages` loaded from storage
- Follow AI SDK's message persistence patterns (load on route entry, not on every render)
- Use AI SDK's error handling patterns (don't reinvent)
- Reference: ai-sdk documentation for conversation restoration, abort handling, error recovery

</specifics>

<deferred>
## Deferred Ideas

These are new capabilities, not stabilization:
- Virtualization for long conversations (Phase 5)
- Advanced retry strategies with backoff (new phase if needed)
- Comprehensive test suite (can add during stabilization but not primary goal)
- Performance optimizations beyond correctness fixes
- New UI features or interactions

</deferred>

---

*Phase: 02.2-stabilization-and-refactor*
*Context gathered: 2026-02-18*
