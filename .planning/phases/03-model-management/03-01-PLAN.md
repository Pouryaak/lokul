---
phase: 03-model-management
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/store/modelStore.ts
  - src/store/conversationModelStore.ts
  - src/lib/storage/conversations.ts
  - src/routes/ChatRoute.tsx
  - src/routes/ChatDetailRoute.tsx
  - src/lib/storage/settings.ts
  - src/App.tsx
autonomous: true
requirements:
  - MODEL-03
  - MODEL-04
  - MODEL-08
  - FIRST-06
must_haves:
  truths:
    - "Opening a conversation uses that conversation's saved model target."
    - "New chats default to Smart mode without a post-chat Smart prompt flow."
    - "Switching target model keeps the same thread and only affects future responses."
  artifacts:
    - path: "src/store/conversationModelStore.ts"
      provides: "Conversation-scoped model intent, queue orchestration, and requested-vs-loaded state"
    - path: "src/routes/ChatDetailRoute.tsx"
      provides: "Route hydration from conversation.model and runtime target sync"
    - path: "src/routes/ChatRoute.tsx"
      provides: "New conversation creation with Smart-default model selection"
    - path: "src/lib/storage/settings.ts"
      provides: "Smart-default settings replacing Quick-first bootstrap behavior"
  key_links:
    - from: "src/routes/ChatDetailRoute.tsx"
      to: "src/store/conversationModelStore.ts"
      via: "hydrate/request calls for active conversation"
      pattern: "hydrate.*conversation|setActiveConversation"
    - from: "src/store/conversationModelStore.ts"
      to: "src/lib/storage/conversations.ts"
      via: "model persistence update for one conversation"
      pattern: "saveConversation|updateConversation"
    - from: "src/App.tsx"
      to: "src/lib/storage/settings.ts"
      via: "bootstrap default model decision"
      pattern: "defaultModel|autoLoad"
---

<objective>
Establish conversation-scoped model orchestration and Smart-default startup behavior so model intent no longer leaks across conversations.

Purpose: Replace global-only model semantics with per-conversation source of truth while honoring locked Smart-default product direction.
Output: A runtime/store foundation that routes, persists, and loads model targets per conversation with seamless in-thread switching semantics.
</objective>

<execution_context>
@/Users/poak/.config/opencode/get-shit-done/workflows/execute-plan.md
@/Users/poak/.config/opencode/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-model-management/03-CONTEXT.md
@.planning/phases/03-model-management/03-RESEARCH.md
@.planning/phases/03-model-management/03-NOTES.md
@.planning/phases/02.2-stabilization-and-refactor/02.2-11-SUMMARY.md
@src/store/modelStore.ts
@src/lib/storage/conversations.ts
@src/routes/ChatRoute.tsx
@src/routes/ChatDetailRoute.tsx
@src/lib/storage/settings.ts
@src/App.tsx
</context>

<tasks>

<task type="auto">
  <name>Task 1: Build conversation-scoped model orchestration state</name>
  <files>src/store/conversationModelStore.ts, src/store/modelStore.ts, src/lib/storage/conversations.ts</files>
  <action>Create `conversationModelStore` to own `activeConversationId`, `requestedModelByConversation`, `engineLoadedModelId`, `downloadLifecycleByModel`, and a single-concurrency queue. Implement request API that persists model target for only the active conversation, enqueues undownloaded targets, and keeps current generation model until target becomes ready. Add lifecycle states exactly as locked decision requires: Queued, Downloading, Compiling, Ready, Failed, Canceled. Reuse existing model engine load/cancel paths and Result-first error handling patterns from 02.2; do not introduce new queue libraries. Add/update storage helper logic so model-only persistence does not reorder sidebar by mutating `updatedAt` unless message activity changed.</action>
  <verify>npm run type-check && npm run lint</verify>
  <done>Store exposes deterministic conversation-scoped switch APIs, queue executes one-by-one, and model-only updates preserve sidebar ordering stability.</done>
</task>

<task type="auto">
  <name>Task 2: Wire routes and bootstrap to Smart-default conversation semantics</name>
  <files>src/routes/ChatRoute.tsx, src/routes/ChatDetailRoute.tsx, src/lib/storage/settings.ts, src/App.tsx</files>
  <action>Update `/chat` creation to default new conversations to Smart mode (`Llama-3.2-3B-Instruct-q4f16_1-MLC`) and remove Quick-first fallback/autoload behavior. On `/chat/:id`, hydrate runtime request state from `conversation.model`, and when a model switch is requested mid-thread keep the conversation ID/thread unchanged so only future responses use the new model. Replace FIRST-06 prompt path with Smart-as-default behavior per locked decision (research recommended prompt deprecation; user decision is authoritative). Keep route-driven conversation ownership and 02.2 cancellation/error guardrails intact.</action>
  <verify>npm run type-check && npm run lint && npm run test</verify>
  <done>New chats start with Smart as target, opening any conversation restores its saved model target, and model switching does not reload page or fork/create a new thread.</done>
</task>

</tasks>

<verification>
1. Open `/chat`, confirm new conversation persists Smart model id.
2. Open two conversations with different saved model targets and verify each route hydration restores the correct target.
3. Switch model while staying on same conversation id and confirm only subsequent messages use the new model target.
</verification>

<success_criteria>
- Conversation model intent is route-scoped and persisted per conversation.
- Smart-default behavior replaces post-chat Smart prompt dependency.
- Runtime no longer relies on a single global active model for all conversations.
</success_criteria>

<output>
After completion, create `.planning/phases/03-model-management/03-model-management-01-SUMMARY.md`
</output>
