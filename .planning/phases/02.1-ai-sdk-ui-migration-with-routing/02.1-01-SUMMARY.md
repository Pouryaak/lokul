---
phase: 02.1-ai-sdk-ui-migration-with-routing
plan: 01
subsystem: ai
requires: []
provides:
  - ai-sdk-ui-transport
  - use-ai-chat-hook
affects:
  - src/lib/ai/webllm-transport.ts
  - src/hooks/useAIChat.ts
  - package.json
tech-stack:
  added:
    - @ai-sdk/react@3.0.92
    - ai@6.0.90
  patterns:
    - ChatTransport interface implementation
    - Custom transport for local inference
    - Hook wrapper pattern for AI SDK UI
key-files:
  created:
    - src/lib/ai/webllm-transport.ts
    - src/hooks/useAIChat.ts
  modified:
    - package.json
decisions:
  - Use ChatTransport interface from ai package for WebLLM integration
  - Yield text-start, text-delta, text-end chunks for proper streaming
  - Store modelId in transport for future model switching support
  - Use conversationId as chat ID for AI SDK UI state management
metrics:
  duration: 15
  tasks: 3
  files: 3
  commits: 3
---

# Phase 02.1 Plan 01: AI SDK UI Integration - Transport Layer

## Summary

Installed AI SDK UI and created the custom WebLLM transport that bridges WebLLM's streaming inference with AI SDK UI's state management. This is the foundation for all AI SDK UI integration, enabling true streaming without the batch-then-stream pattern.

## One-Liner

AI SDK UI transport layer with WebLLM custom transport and useAIChat hook for true streaming inference.

## What Was Built

### 1. AI SDK UI Dependencies (@ai-sdk/react, ai)

Installed the core AI SDK UI packages:
- `@ai-sdk/react@3.0.92` - React hooks for AI chat (useChat)
- `ai@6.0.90` - Core types and utilities (ChatTransport, UIMessage, UIMessageChunk)

### 2. WebLLMTransport Class (src/lib/ai/webllm-transport.ts)

Custom ChatTransport implementation that:
- Implements the `ChatTransport<UIMessage>` interface from the `ai` package
- Bridges WebLLM's `AsyncGenerator<string>` tokens with AI SDK UI's `UIMessageChunk` stream format
- Converts UIMessage array to WebLLM message format (role and content extraction)
- Yields proper streaming chunks: `text-start`, `text-delta`, `text-end`
- Handles errors by yielding `error` chunks
- Supports abort/cancellation via AbortController
- Returns null for `reconnectToStream()` (WebLLM doesn't support stream resumption)

Key methods:
- `sendMessages()` - Main streaming method that calls inferenceManager.generate()
- `reconnectToStream()` - Returns null (not supported by WebLLM)
- `abort()` - Stops generation via inferenceManager.abort()
- `getModelId()` - Returns the model ID for this transport instance
- `convertToWebLLMMessages()` - Converts UIMessage[] to WebLLM format
- `extractTextContent()` - Extracts text from message parts

### 3. useAIChat Hook (src/hooks/useAIChat.ts)

Wrapper hook that configures `useChat` from `@ai-sdk/react` with the WebLLM transport:
- Accepts `conversationId`, `modelId`, and `messages` options
- Creates WebLLMTransport instance with the specified model
- Returns full useChat helpers: messages, sendMessage, status, error, etc.
- Serves as the bridge between the model store and AI SDK UI state management

## Verification

All verification criteria met:
- [x] @ai-sdk/react and ai packages installed
- [x] WebLLMTransport implements ChatTransport interface correctly
- [x] useAIChat hook wraps useChat with WebLLM transport
- [x] TypeScript compilation passes for new files
- [x] No runtime errors on import

## Commits

| Hash | Type | Description |
|------|------|-------------|
| 25894f1 | chore | Install AI SDK UI dependencies |
| f426829 | feat | Create WebLLM custom transport for AI SDK UI |
| 6106380 | feat | Create useAIChat hook |

## Deviations from Plan

None - plan executed exactly as written.

## Key Implementation Details

### Streaming Flow

```
User Input
    |
    v
useAIChat.sendMessage()
    |
    v
WebLLMTransport.sendMessages()
    |
    v
convertToWebLLMMessages() -> WebLLM format
    |
    v
inferenceManager.generate() -> AsyncGenerator<string>
    |
    v
Yield UIMessageChunk events:
  - { type: 'text-start', id }
  - { type: 'text-delta', delta, id }
  - { type: 'text-end', id }
    |
    v
AI SDK UI updates messages state
    |
    v
React re-renders with streaming text
```

### Message Format Conversion

AI SDK UI UIMessage format:
```typescript
{
  id: string;
  role: 'system' | 'user' | 'assistant';
  parts: Array<{ type: 'text', text: string }>;
}
```

WebLLM format:
```typescript
{
  role: 'system' | 'user' | 'assistant';
  content: string;
}
```

The transport extracts text content from message parts and maps roles directly (they match between formats).

## Next Steps

With the transport layer complete, the next plans in Phase 02.1 can:
1. Use `useAIChat` hook in chat components
2. Implement routing (/chat, /chat/[id])
3. Migrate existing chat state to AI SDK UI
4. Add conversation persistence with AI SDK UI

## Self-Check: PASSED

- [x] src/lib/ai/webllm-transport.ts exists
- [x] src/hooks/useAIChat.ts exists
- [x] package.json includes @ai-sdk/react and ai
- [x] All commits exist (25894f1, f426829, 6106380)
- [x] TypeScript compiles without errors in new files
